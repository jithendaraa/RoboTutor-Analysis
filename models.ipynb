{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified: 'Data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-71d05af69053>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ls'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'Data'"
     ]
    }
   ],
   "source": [
    "# Data handling and processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Sklearn imports\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Model imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# File mgmt\n",
    "import os\n",
    "\n",
    "# misc\n",
    "import time\n",
    "\n",
    "os.chdir('Data')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jithe\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (3,7,37,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "path = 'Transactions_Village114/ds3170_tx_All_Data_5208_2019_1211_082948.txt'\n",
    "df = pd.read_csv(path, sep=\"\\t\")\n",
    "cols = ['Anon Student Id', 'Session Id', 'Duration (sec)', 'Level (Tutor Name)', 'Level (Tutor)', 'Problem Name', 'Problem View','Step Name', 'Attempt At Step','Is Last Attempt','Outcome', 'Input','CF (File)','CF (Matrix)','CF (Matrix Level)', 'CF (Matrix Order)', 'CF (Total Activity Problems)']\n",
    "df = df[cols]\n",
    "bubble_pop_df = df[df['Level (Tutor Name)'] == 'bubble_pop']\n",
    "bpop_math_df = bubble_pop_df[bubble_pop_df['CF (Matrix)'] == 'math'] #6172\n",
    "\n",
    "# X and y -> inputs and outputs for the classification model\n",
    "cols = ['Duration (sec)', 'Level (Tutor)', 'Attempt At Step', 'CF (Matrix Level)', 'CF (Matrix Order)', 'Outcome']\n",
    "X = bpop_math_df[cols]\n",
    "y = X[['Outcome']]\n",
    "X = X.drop(['Outcome'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean duration (sec) columns: Convert all values to float, if not able to convert set value in that row as duration_mean\n",
    "def clean_duration_col_with_mean(X):\n",
    "    strings = 0\n",
    "    ints = 0\n",
    "    floats = 0\n",
    "    other = 0\n",
    "    cnt = 0\n",
    "    sums = 0\n",
    "    posn = []\n",
    "    X_duration_arr = X['Duration (sec)'].array\n",
    "\n",
    "    for i in range(len(X_duration_arr)):\n",
    "        if isinstance(X_duration_arr[i], int):\n",
    "            ints += 1\n",
    "        elif isinstance(X_duration_arr[i], str):\n",
    "            strings += 1\n",
    "            try:\n",
    "                X_duration_arr[i] = float(X_duration_arr[i])\n",
    "            except ValueError:\n",
    "#                 print(\"Cant convert to a float\", X_duration_arr[i], \"Position: \",i)\n",
    "                posn.append(i)\n",
    "        elif isinstance(X_duration_arr[i], float):\n",
    "            floats += 1\n",
    "    \n",
    "        if isinstance(X_duration_arr[i], float):\n",
    "            sums += X_duration_arr[i]\n",
    "            cnt += 1\n",
    "\n",
    "    duration_mean = sums/cnt\n",
    "    for i in range(len(posn)):\n",
    "        X_duration_arr[posn[i]] = duration_mean\n",
    "\n",
    "    for i in range(len(X_duration_arr)):\n",
    "        col = bpop_math_df.columns.get_loc('Duration (sec)')\n",
    "        val = X_duration_arr[i]\n",
    "        X.iloc[i, col] = val\n",
    "    \n",
    "    return X\n",
    "\n",
    "# Ordinal encodes a column\n",
    "def ordinal_encode_col(X, colname):\n",
    "    enc = OrdinalEncoder()\n",
    "    level_tutor = X[colname].tolist()\n",
    "    tutor_level_2dlist = []\n",
    "    for i in range(len(level_tutor)):\n",
    "        tutor_level_2dlist.append([level_tutor[i]])\n",
    "\n",
    "    enc.fit(tutor_level_2dlist)\n",
    "\n",
    "    col = X.columns.get_loc(colname)\n",
    "    num_entries = X.count()[colname]\n",
    "    for i in range(num_entries):\n",
    "        val = X.iloc[i, col]\n",
    "        val = enc.transform([[val]])[0][0]\n",
    "        X.iloc[i, col] = val\n",
    "    \n",
    "    return X\n",
    "\n",
    "def rfe(X_train, y_train, apply_rfe):\n",
    "    if apply_rfe == False:\n",
    "        return\n",
    "    data_final_vars=X_train.columns.values.tolist()\n",
    "    y_=['y']\n",
    "    X=[i for i in data_final_vars if i not in y_]\n",
    "    logreg = LogisticRegression()\n",
    "    rfe = RFE(logreg, 20)\n",
    "    rfe = rfe.fit(X_train, y_train)\n",
    "#     print(\"RFE Support: \",rfe.support_)\n",
    "#     print(\"RFE Ranking: \", rfe.ranking_)\n",
    "\n",
    "# incorrect -> 0, correct -> 1\n",
    "# set_zero = \"INCORRECT\" means incorrect will be set to 0 and other value as 1\n",
    "def encode_outputs(y, colname, set_zero):\n",
    "    col = y.columns.get_loc(colname)\n",
    "    for i in range(y.count()[colname]): \n",
    "        val = y.iloc[i, col]\n",
    "        if val == set_zero:\n",
    "            val = 0\n",
    "        else: \n",
    "            val = 1\n",
    "        y.iloc[i, col] = val\n",
    "    \n",
    "    return y\n",
    "\n",
    "def encode_categorical_cols(X, encoder, col):\n",
    "\n",
    "#   Ordinally encode categorical columns\n",
    "    if encoder == \"ordinal\":\n",
    "        for i in range(len(col)):\n",
    "            X = ordinal_encode_col(X, col[i])\n",
    "    \n",
    "    return X\n",
    "\n",
    "def normalize_data(X, norm):\n",
    "    if norm == 'l1':\n",
    "        X = sklearn.preprocessing.normalize(X, norm='l1', axis=1, copy=True, return_norm=False)\n",
    "        X = pd.DataFrame(data=X, columns=cols[:len(cols)-1])\n",
    "    \n",
    "    elif norm == 'l2':\n",
    "        X = sklearn.preprocessing.normalize(X, norm='l2', axis=1, copy=True, return_norm=False)\n",
    "        X = pd.DataFrame(data=X, columns=cols[:len(cols)-1])\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def run_logistic_regression(X, y, test_split, apply_rfe):\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_split)\n",
    "    rfe(X_train, y_train, apply_rfe)\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    performance = 100 * logreg.score(X_test, y_test)\n",
    "#     print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(performance))\n",
    "    return performance\n",
    "    \n",
    "def run_k_neighbors_classifier(X, y, test_split, apply_rfe, neighbors):\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_split)\n",
    "    rfe(X_train, y_train, apply_rfe)       \n",
    "    neigh = KNeighborsClassifier(n_neighbors=neighbors)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    performance = 100 * neigh.score(X_test, y_test)\n",
    "#     print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(performance))\n",
    "    return performance\n",
    "\n",
    "def run_svm(X, y, test_split, apply_rfe, svc_kernel):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_split)\n",
    "    rfe(X_train, y_train, apply_rfe)   \n",
    "    svm_model = svm.SVC(kernel=svc_kernel)\n",
    "    print(\"CREATE MODEL\")\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    print(\"FIT\")\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    perf = 100 * metrics.accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\",perf)\n",
    "    return perf\n",
    "\n",
    "def run_nn(X, y, test_split, lr, epochs):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # Make everything as float type\n",
    "\n",
    "    X_train['Duration (sec)'] = X_train['Duration (sec)'].astype(float)\n",
    "    X_train['Level (Tutor)'] = X_train['Level (Tutor)'].astype(float)\n",
    "    X_train['CF (Matrix Level)'] = X_train['CF (Matrix Level)'].astype(float)\n",
    "    X_train['CF (Matrix Order)'] = X_train['CF (Matrix Order)'].astype(float)\n",
    "\n",
    "    X_test['Duration (sec)'] = X_test['Duration (sec)'].astype(float)\n",
    "    X_test['Level (Tutor)'] = X_test['Level (Tutor)'].astype(float)\n",
    "    X_test['CF (Matrix Level)'] = X_test['CF (Matrix Level)'].astype(float)\n",
    "    X_test['CF (Matrix Order)'] = X_test['CF (Matrix Order)'].astype(float)\n",
    "\n",
    "    # Convert to torch tensors\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train.values).float()\n",
    "    X_test_tensor = torch.tensor(X_test.values).float()\n",
    "    y_train_tensor = torch.tensor(y_train).float()\n",
    "    y_test_tensor = torch.tensor(y_test).float()\n",
    "    \n",
    "    \n",
    "    # Model class\n",
    "    class StudentNet(nn.Module):\n",
    "    \n",
    "        def __init__(self, input_size, hidden1_size, hidden2_size, num_classes):\n",
    "            super(StudentNet, self).__init__()\n",
    "            self.fc1 = nn.Linear(5, hidden1_size)\n",
    "            self.fc2 = nn.Linear(hidden1_size, hidden2_size)\n",
    "            self.fc3 = nn.Linear(hidden1_size, num_classes)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "    \n",
    "        def predict(self,x):\n",
    "            pred = F.softmax(self.forward(x))\n",
    "            ans = []\n",
    "            #Pick the class with maximum proba\n",
    "            for t in pred:\n",
    "                if t[0]>t[1]:\n",
    "                    ans.append(0)\n",
    "                else:\n",
    "                    ans.append(1)\n",
    "            return torch.tensor(ans)\n",
    "    \n",
    "    model = StudentNet(5, 20, 20, 2)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for i in range(epochs):\n",
    "    \n",
    "        #Predict the output for Given input\n",
    "        y_pred = model.forward(X_train_tensor)\n",
    "        y_train_tensor = y_train_tensor\n",
    "        loss = loss_function(y_pred, y_train_tensor)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i%1000 == 0:\n",
    "            print(\"Loss: \", loss.item())\n",
    "\n",
    "    perf = 100 * accuracy_score(model.predict(X_test_tensor),y_test_tensor)\n",
    "    print(\"ACCURACY: \", perf, \"%\")\n",
    "    return perf\n",
    "    \n",
    "\n",
    "def run_algo(algo, X, y, clean_method, encoder, norm, test_split, apply_rfe, categorical_cols, neighbors, svc_kernel, lr, epochs):\n",
    "    \n",
    "    if clean_method == \"mean\":\n",
    "        X = clean_duration_col_with_mean(X)\n",
    "    \n",
    "    X = encode_categorical_cols(X, encoder, categorical_cols)\n",
    "    X = normalize_data(X, norm)\n",
    "    y = encode_outputs(y, 'Outcome', 'INCORRECT').values.ravel()\n",
    "    perf = 0\n",
    "    if algo == \"logistic_regression\":\n",
    "        perf = run_logistic_regression(X, y, test_split, apply_rfe)\n",
    "    \n",
    "    elif algo == \"k_neighbors_classifier\":\n",
    "        perf = run_k_neighbors_classifier(X, y, test_split, apply_rfe, neighbors)\n",
    "    \n",
    "    elif algo == \"svm\":\n",
    "        perf = run_svm(X, y, test_split, apply_rfe, svc_kernel)\n",
    "        \n",
    "    elif algo == \"nn\":\n",
    "        perf = run_nn(X, y, test_split, lr, epochs)\n",
    "      \n",
    "    return perf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean median or mode (#FIXME: only supports mean for now)\n",
    "clean_method = \"mean\" \n",
    "\n",
    "# ordinal, onehot etc.. (#FIXME: only supports ordinal encoding for now)\n",
    "encoder = \"ordinal\" \n",
    "\n",
    "# cols that are categories rather than numbers and have to be encoded\n",
    "categorical_cols = ['Level (Tutor)']\n",
    "\n",
    "# none, l1, l2 etc..\n",
    "norm = \"none\" \n",
    "\n",
    "# set True to apply Recursive Feature Elimination\n",
    "apply_rfe = True\n",
    "\n",
    "test_split = 0.2\n",
    "num_runs = 10\n",
    "lr = 0.08\n",
    "epochs = 10000\n",
    "\n",
    "# k neighbors classifier\n",
    "neighbors = 5\n",
    "\n",
    "# linear, poly, rbf, sigmoid\n",
    "svc_kernel = 'linear'\n",
    "\n",
    "# Supports logistic_regression, k_neighbors_classifier, svm, nn\n",
    "algo = \"logistic_regression\"\n",
    "\n",
    "# used to store performance of each run in num_runs\n",
    "total_perfs = []\n",
    "\n",
    "for i in range(num_runs):\n",
    "    X = bpop_math_df[cols]\n",
    "    X = X.sample(frac=1).reset_index(drop=True)\n",
    "    y = X[['Outcome']]\n",
    "    X = X.drop(['Outcome'], axis=1)\n",
    "    perf = run_algo(algo, X, y, clean_method, encoder, norm, test_split, apply_rfe, categorical_cols, neighbors, svc_kernel, lr, epochs)\n",
    "    total_perfs.append(perf)\n",
    "\n",
    "avg_perf = sum(total_perfs)/num_runs\n",
    "print(\"Avg. performance over \", num_runs, \"runs: \", avg_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.04048582995952 %( 68.2591093117409 - 70.8502024291498 )\n"
     ]
    }
   ],
   "source": [
    "print(avg_perf, \"%(\", min(total_perfs), \"-\", max(total_perfs) ,\")\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
